---
layout: post
title:  "AI 分享"
date:   2025-03-29 02:05:09 +0800
categories: post
---

<div align="center">
<img src="/assets/imgs/ai_share/bg.jpg" width="100%"/>
</div>
<div align="center">
<span style="font-size: 14px">黑客帝国动画版（2003）海报</span>
</div>

### **引子**

近年，AI 对不少行业都形成了一定的冲击，大家对 AI 的热情也愈发高涨。
写这篇文章的目的是希望以简单直观的方式介绍大模型领域的常见概念，比如各种时髦的名词与新兴技术（像是 AI Agent、Function Call、MCP 等）。
帮助大家了解当前的热点技术与工具，当工作中涉及 AI 时，可以有一定的判断。
这篇文章主要讲解大模型相关技术与工具的背景、功能与使用场景，对于这些背后的原理只做简单阐述，如果有兴趣可以进一步阅读参考链接。

### **大模型的工作原理**

在阐述大模型相关的技术与工具前，需要大家首先对大模型的工作原理有一定了解。
对于大模型的详细工作原理可参阅文献[^llm_workflow]。
其实大模型的工作原理很简单，就是四个字“文字接龙”，大模型根据输入的 Prompt 计算出下一个可能的字或词，再用此 Prompt 附加上新产生的字或词作为大模型新的输入，重复此过程直至得到完整的结果，大模型的简易工作原理如下图所示：

<div align="center">
<img src="/assets/imgs/ai_share/llm_workflow.png" width="75%"/>
</div>
<div align="center">
<span style="font-size: 14px">大模型的工作流程</span>
</div>

举个例子，向大模型输入 Prompt“今天天气怎么样？”，大模型会按以下流程进行工作：
1. 大模型会首先对 Prompt 进行分词处理，比如将其分解为 token 序列“今天”、“天气”、“怎么样”与“？”，对于分词的详细介绍可参阅文献[^tokenizer]；
2. 大模型随后对 token 进行向量化处理，将每个 token 转化为一个向量，比如“今天”被转化为向量$[1.1, 1.2, 2.0]$；
3. 大模型再将向量输入至神经网络进行计算得到一个新的 token，如“今天”；
4. 大模型再将新的 token 附加至之前的 token 序列，得到新的 token 序列“今天”、“天气”、“怎么样”、“？”与“今天”；
5. 重复步骤 2-4 直至得到最终结果。

[^llm_workflow]: [The Illustrated GPT-2 (Visualizing Transformer Language Models)](https://jalammar.github.io/illustrated-gpt2/)
[^tokenizer]: [LLM大语言模型之Tokenization分词方法（WordPiece，Byte-Pair Encoding (BPE)，Byte-level BPE(BBPE)原理及其代码实现）](https://zhuanlan.zhihu.com/p/652520262)

### **Function Call**

- [MCP Introduction](https://modelcontextprotocol.io/introduction)

大模型可以使用工具

### 参考资料
